<!DOCTYPE HTML>
<!--
	Spectral by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>CG - Humanoid</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="../assets/css/main.css" />
		<noscript><link rel="stylesheet" href="../assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Page Wrapper -->
			<div id="page-wrapper">

				<!-- Header -->
					<header id="header">
						<h1>Humanoid Robotics</a></h1>
						<nav id="nav">
							<ul>
								<li class="special">
									<a href="#menu" class="menuToggle"><span>Menu</span></a>
									<div id="menu">
										<ul>
											<li><a href="../index.html">Home</a></li>
											<li><a href="../about.html">About Me</a></li>
											<li><a href="../resume.html">Resume</a></li>
											<li class="dropdown">
												<label for="projects-toggle" class="toggle-label">
													Projects <span class="arrow"></span>
												</label>
												<input type="checkbox" id="projects-toggle">
												<ul>
												  <li><a href="../projects.html">&nbsp;&nbsp;All Projects</a></li>
												  <li><a href="AlphabetAstronauts.html">&nbsp;&nbsp;Alphabet Astronauts</a></li>
												  <li><a href="AutoGrader.html">&nbsp;&nbsp;Auto Grader</a></li>
												  <li><a href="Blocked.html">&nbsp;&nbsp;Blocked</a></li>
												  <li><a href="Jelly.html">&nbsp;&nbsp;GHOST Jelly</a></li>
												  <li><a href="GC3.html">&nbsp;&nbsp;Humanoid Robotics</a></li>
												  <li><a href="roxie.html">&nbsp;&nbsp;Roxie</a></li>
												  <li><a href="SpaceRobotics.html">&nbsp;&nbsp;Space Robotics</a></li>
												  <li><a href=""></a></li>
												  <li><a href="backyard.html">&nbsp;&nbsp;Backyard Remodel</a></li>
												  <li><a href="bar.html">&nbsp;&nbsp;Bar</a></li>
												  <li><a href="PC.html">&nbsp;&nbsp;Custom PC</a></li>
												  <li><a href="Deck.html">&nbsp;&nbsp;Deck</a></li>
												  <li><a href="Jeep.html">&nbsp;&nbsp;Jeep</a></li>
												</ul>
											</li>
											<li><a href="../contact.html">Connect With Me</a></li>
										</ul>
									</div>
								</li>
							</ul>
						</nav>
					</header>

				<!-- Main -->
					<article id="banner">
						<header>
							<h2>Attempted a VR solution to grand challenge: Multimodal Synchronization of Humanoids</h2>
                            <span class="image">
                                <img src="../images/MH GC3.jpeg" alt=""  style="width: 100%;" />
                            </span>
						</header>
                    </article><br>
                    <section>
						<div class="table-wrapper" align="left">
							<table>
								<tbody>
									<tr>
										<tr>
											<td>Lessons Learned</td>
											<td>This course project was focused on solving a humanoid robotics grand challenge. Our group chose to attempt to solve
												the synchronization of multimodal behaivors. Our task was to create a simulated humanoid and allow it to freely interact
												with a human user in VR. We created an environment in Unreal Engine 5 and our humanoid was designed with MetaHuman. 
												<br><br> My roles on this project were:
												<ul class="custom-indent">
													<li>Unreal Engine 5 environment design</li>
													<li>Metahuman design</li>
													<li>Incorporating chatGPT with our MetaHuman for speech capabilities</li>
													<li>MetaHuman motion targeting in Unreal Engine 5</li>
													<li>Abstracting room attributes for less of a 'hard coded' solution</li>
													
												</ul>
												More details about the project are below.
											</td>
										</tr>
										<tr>
											<td></td>
										</tr>
										<tr>
											<td></td>
										</tr>
										<tr>
											<td>Introduction</td>
											<td>One of the biggest current challenges for humanoid robot development
												is conquering the Uncanny Valley. It is a phenomenon that robots' 
												affinity decreases as it is becoming more and more like a human. Before 
												solving this problem, we need to first conquer the problem of synchronizing the robot's 
												multimodal behaviors since it is essential for information exchange between it and the 
												user. To solve this grand challenge, we propose a solution that mainly uses neural 
												networks that considers different scenarios. The method combines GPT3 (third-generation
												Generative Pre-trained Transformer), predefined keywords trigger command, and Mixamo,
												a database that uses motion-captured animations. Our final result allows the user to 
												interact with the humanoid in Unreal Engine 5 and give it commands. The humanoid is 
												able to execute these commands.
											</td>
										</tr>
										<tr>
											<td></td>
										</tr>
										<tr>
											<td></td>
										</tr>
										<tr>
											<td>Methods</td>
											<td>Our method requires a combination of six sub-steps, and each requires a different technique or software. 
												The first step is to set up the environment, acquiring the coordinates of items. The second step is using 
												a neural network to train the walking movement of the humanoid robot. The third step is using predefined 
												action scripts to simulate the action of picking up the specified item. The fourth step is to combine 
												walking with the action of picking things up, making the entire process smooth. The fifth step is to 
												reconstruct the entire action in a VR environment, and the user (human) should be able to clearly see 
												the action of the robot. The final step is to integrate GPT3 which allows the robot to verbally interact 
												with the user.
												<br><br>
												<ul class="custom-indent">
													<li>
														The environment used for the project is AI2THOR, which is an open-source virtual environment 
														for AI agents that simulates realistic 3D scenes. AI2THOR records the coordinates of each item, 
														including the item being picked up, and these coordinates are then imported into Unreal Engine 
														5 for further processing. The combination of these two tools allows for the creation of a highly 
														detailed and realistic virtual environment for the robot to operate in.
													</li><br>
													<li>
														To generate movement variants for the robot's walking, a neural network is used. This neural 
														network is trained using data obtained from the DeepMimic database, which contains a vast array 
														of motion-capture data. The neural network is trained to generate variations in walking patterns 
														that are both efficient and safe for the robot to perform.
													
													</li><br>
													<li>
														To simulate the action of picking up the item, predefined action scripts are used. These scripts 
														dictate the movements that the robot needs to perform to successfully pick up an object. The walking 
														and picking actions are then combined for smooth execution, ensuring that the robot can move around 
														the environment with ease and complete its tasks efficiently.
													
													</li><br>
													<li>
														The entire process is reconstructed in a virtual reality (VR) environment. This allows for a 
														highly immersive and interactive experience, where the user can see the robot in action and 
														even interact with it verbally. To enable verbal interaction, GPT-3 is integrated into the system. 
														This powerful language model can be used to generate responses to user queries, allowing for a 
														seamless and natural interaction between the user and the robot. Overall, the combination of these 
														technologies creates a highly advanced and realistic simulation environment that is ideal for 
														testing and training robotic systems.

													</li>
												</ul>
											</td>
										</tr>
										<tr>
											<td></td>
										</tr>
										<tr>
											<td></td>
										</tr>
										<tr>
											<td>Results</td>
											<td>Our blueprint enables the user to chat and command our humanoid in Unreal Engine 5, providing 
												a quick and accurate response from the robot, and making the user feel comfortable interacting 
												with it. The integration of GPT3 provides a prompt response to user input, though response time 
												may vary depending on the complexity of the question. Keyword-sensitive commands allow for accurate 
												execution of predefined actions, and the robot can dynamically adjust its path to avoid obstacles. 
												Each action is linked to a specific Mixamo action neural network for precise execution. However, 
												the accuracy of GPT3's responses to commands may vary.<br><br>

												<div class="box alt">
													<div class="row gtr-50 gtr-uniform">
														<div class="col-12"><span class="image fit"><img src="../videos/GC3-Demo1.gif" alt=""  /></span>
														<figcaption>Demonstration of trained Deep Mimic network</figcaption></div>
													</div><br><br>
													<div class="row gtr-50 gtr-uniform">
														<div class="col-12"><span class="image fit"><img src="../videos/GC3-Demo2.gif" alt=""  /></span>
														<figcaption>Linked MetaHuman body motion and facial motion matching speech</figcaption></div>
													</div><br><br>
												</div>
											</td>
										</tr>
										<tr>
											<td></td>
										</tr>
										<tr>
											<td></td>
										</tr>
										<tr>
											<td>Discussion</td>
											<td>
												
											<br><br>	
											</td>
										</tr>
									</tr>
								</tbody>
							</table>
						</div>
					</section>

						<!-- Footer -->
						<footer id="footer">
							<p class="copyright">
								Thank you for your patience, this site is still under construction.
							</p>
							<ul class="icons">
								<li><a href="https://linkedin.com/in/connorgeshan" target="_blank" class="icon brands fa-linkedin"><span class="label">LinkedIn</span></a></li>
								<li> | </li>
								<li><a href="https://github.com/cgeshan" target="_blank" class="icon brands fa-github"><span class="label">Github</span></a></li>
								<li> | </li>
								<li><a href="../contact.html" class="icon solid fa-envelope"><span class="label">Email</span></a></li>
							</ul>
							<ul class="copyright">
								<li>&copy; Connor Geshan</li><li>Design: <a href="http://html5up.net">HTML5 UP</a></li>
							</ul>
						</footer>


			</div>

		<!-- Scripts -->
			<script src="../assets/js/jquery.min.js"></script>
			<script src="../assets/js/jquery.scrollex.min.js"></script>
			<script src="../assets/js/jquery.scrolly.min.js"></script>
			<script src="../assets/js/browser.min.js"></script>
			<script src="../assets/js/breakpoints.min.js"></script>
			<script src="../assets/js/util.js"></script>
			<script src="../assets/js/main.js"></script>

	</body>
</html>
